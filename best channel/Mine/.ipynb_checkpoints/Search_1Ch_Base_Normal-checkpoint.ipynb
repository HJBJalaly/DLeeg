{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "v_9QlgWXuZ2E",
    "outputId": "48e12a5b-f646-40cd-fb35-735daece5b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /home/hamed/anaconda3/envs/mne/lib/python3.6/site-packages (0.16.1)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ugNHdREkvO6h",
    "outputId": "d757bf5c-966c-40e4-a719-d31b9a4df2d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSearch among 24 selected channels to find best accuracy with only one channel\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Search among 24 selected channels to find best accuracy with only one channel\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs\n",
    "from mne import io\n",
    "from mne import viz\n",
    "from mne import Epochs, io, pick_types\n",
    "from mne.event import define_target_events\n",
    "from mne.time_frequency import psd_welch\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtvZeqTcuZ2M"
   },
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "subject_number=2\n",
    "task_number=1\n",
    "task_time = 60\n",
    "sampel_number_per_sec =  160 # sampel rate\n",
    "total_sampel_number =  sampel_number_per_sec *task_time # 60*160\n",
    "sample_shift = 4 #step len\n",
    "window_len= 20\n",
    "Search_Space_Channel = [21,23,29]#,31,33,35,36,40,8,10,12,41,46,48,50,52,54,60,61,62]\n",
    "\n",
    "# Channel Indexes:\n",
    "#   Fp1,21\n",
    "#   Fp2,23\n",
    "#   F7,29\n",
    "#   F3,31\n",
    "#   Fz,33\n",
    "#   F4,35\n",
    "#   F8,36\n",
    "#   T7,40\n",
    "#   C3,8\n",
    "#   Cz,10\n",
    "#   C4,12\n",
    "#   T8,41\n",
    "#   P7,46\n",
    "#   P3,48\n",
    "#   Pz,50\n",
    "#   P4,52\n",
    "#   P8,54\n",
    "#   O1,60\n",
    "#   Oz,61\n",
    "#   O2,62\n",
    "\n",
    "#   T9,42\n",
    "#   T10,43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EMBxiZ8KvXUP",
    "outputId": "e67d058f-4cb9-4eec-8b32-c7b788a30501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/hamed/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S001/S001R01.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n",
      "Extracting EDF parameters from /home/hamed/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S001/S001R02.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n",
      "Extracting EDF parameters from /home/hamed/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S002/S002R01.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n",
      "Extracting EDF parameters from /home/hamed/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S002/S002R02.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n"
     ]
    }
   ],
   "source": [
    "# load dataset in array\n",
    "list_raw_fnames = [[0]*2]*subject_number\n",
    "for x in range(subject_number):\n",
    "    list_raw_fnames[x] = mne.datasets.eegbci.load_data(x+1,[1,2])\n",
    "\n",
    "#list_rawdata1 = np.zeros((subject_number,2), dtype='object')\n",
    "list_rawdata = np.zeros((subject_number,2), dtype='object')\n",
    "\n",
    "for i in range(subject_number):\n",
    "    for j in range(2):\n",
    "        list_rawdata[i][j] = mne.io.read_raw_edf(list_raw_fnames[i][j], preload=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lltZvYULvrvA",
    "outputId": "590789af-c65f-4fef-c396-8a5a3d2a31e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample: 1757\n",
      "Test sample: 585\n"
     ]
    }
   ],
   "source": [
    "# img for each subject\n",
    "subject_img_number = math.floor((total_sampel_number - sampel_number_per_sec) / sample_shift) +1 - window_len +1\n",
    "test_start_index=subject_img_number - math.floor(subject_img_number/4) \n",
    "\n",
    "train_number =  test_start_index \n",
    "test_number = subject_img_number - test_start_index\n",
    "print(\"Train sample:\",train_number)\n",
    "print(\"Test sample:\",test_number)\n",
    "\n",
    "# ch_number = len(list_channel)\n",
    "\n",
    "# train_img = np.zeros((train_number*subject_number, ch_number, window_len + 1, 160), dtype = float)\n",
    "# train_label =[]\n",
    "\n",
    "# test_img = np.zeros((test_number*subject_number, ch_number, window_len, 160), dtype = float)\n",
    "# test_label =[]\n",
    "\n",
    "# print(\"train image dims:\",train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NuDhT0Y1Fqa"
   },
   "outputs": [],
   "source": [
    "def normalize_channel_data(ch , i, ch_min, ch_max):\n",
    "  ch = ((ch - ch_min[i]) / (ch_max[i] - ch_min[i] ))\n",
    "  return ch\n",
    "\n",
    "def ProjectionVector(VecA,VecB):\n",
    "    Projeted_VecB_on_VecA=np.dot(VecA,VecB)/np.dot(VecA,VecA)*VecA\n",
    "    return Projeted_VecB_on_VecA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3514 samples, validate on 0 samples\n",
      "Epoch 1/1\n",
      "3514/3514 [==============================] - 69s 20ms/step - loss: 0.6895 - acc: 0.5216\n",
      "1170/1170 [==============================] - 15s 13ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c491d5594de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mSearchSpaceResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndexCh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mSearchSpaceResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndexCh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mSearchSpaceResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndexCh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mSearchSpaceResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndexCh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "# seacrh all channels\n",
    "SearchSpaceResult=np.zeros((len(Search_Space_Channel),6),dtype = float)\n",
    "\n",
    "for IndexCh in range(len(Search_Space_Channel)):\n",
    "    \n",
    "    #################################################################################################\n",
    "    # Reset Model and Data Arrays\n",
    "    list_channel=[Search_Space_Channel[IndexCh]]\n",
    "    ch_number=len(list_channel)\n",
    "    \n",
    "    train_img = np.zeros((train_number*subject_number, ch_number, window_len + 1, 160), dtype = float)\n",
    "    train_label =[]\n",
    "\n",
    "    test_img = np.zeros((test_number*subject_number, ch_number, window_len, 160), dtype = float)\n",
    "    test_label =[]\n",
    "    \n",
    "    list_rawdataTemp=list_rawdata.copy()\n",
    "\n",
    "    #################################################################################################\n",
    "    # Fill Data Arrays\n",
    "    for s in range(subject_number):\n",
    "\n",
    "        DataAllChannelsRaw, times =(list_rawdataTemp[s][0][:64,:9600])\n",
    "\n",
    "\n",
    "        # Extrac Channel T9 or T10 as Baseline\n",
    "        DataChannelT9Raw =DataAllChannelsRaw[43]# Ch T9 (42) or T10 (43)\n",
    "\n",
    "        ch_max =[]\n",
    "        ch_min =[]\n",
    "        # Extract Selected Channels+ Remove Baseline+ Normailze\n",
    "        DataChannelsRaw   =np.zeros((ch_number,times.size),dtype = float)\n",
    "        DataChannelsNormal=np.zeros((ch_number,times.size),dtype = float)\n",
    "        DataChannelsOrt   =np.zeros((ch_number,times.size),dtype = float)\n",
    "        for i in range(len(list_channel)):\n",
    "            DataChannelsRaw[i]=DataAllChannelsRaw[list_channel[i]].copy() #-DataChannelT9Raw\n",
    "            \n",
    "            ch_max = np.append(ch_max, max(DataChannelsRaw[i])) # max for each cannel\n",
    "            ch_min = np.append(ch_min, min(DataChannelsRaw[i])) # min for each cannel\n",
    "            \n",
    "            DataChannelsNormal[i]=normalize_channel_data(DataChannelsRaw[i].copy(), i, ch_min, ch_max)\n",
    "\n",
    "    \n",
    "        # Orthogonal Channel\n",
    "        DataChannelsOrt[0]=DataChannelsNormal[0]\n",
    "        #DataChannelsOrt[1]=DataChannelsNormal[1]-ProjectionVector(DataChannelsNormal[0],DataChannelsNormal[1])\n",
    "    \n",
    "\n",
    "        for j in range (subject_img_number):\n",
    "            for i in range(len(list_channel)): # فقط کانال های با اندیس مشخص را دربرمیگیرد\n",
    "                for z in range (window_len):\n",
    "                    ExtractedData=DataChannelsOrt[i,0+(j+z)*sample_shift:sampel_number_per_sec+(j+z)*sample_shift]\n",
    "\n",
    "                    if j <test_start_index :\n",
    "                        train_img[s*train_number + j][i][z] = ExtractedData\n",
    "                        if z==window_len-1 :\n",
    "                            train_img[s*train_number + j][i][z+1] = s\n",
    "                    else:\n",
    "                         test_img[s*test_number + j - test_start_index][i][z] = ExtractedData\n",
    "            if j >=test_start_index :\n",
    "                test_label = np.append(test_label, (s))\n",
    "                \n",
    "        \n",
    "    #################################################################################################\n",
    "    #shuffle train img array\n",
    "    train_img_shuffle = train_img.copy()\n",
    "\n",
    "    np.random.shuffle(train_img_shuffle)\n",
    "\n",
    "    train_img_2 = np.zeros((train_number*subject_number, ch_number, window_len, 160), dtype = float)\n",
    "\n",
    "    # img label \n",
    "    train_img_shuffle_len =len(train_img_shuffle)\n",
    "    for i in range(train_img_shuffle_len):\n",
    "        train_label = np.append(train_label, (train_img_shuffle[i][0][window_len][0] ))\n",
    "        for j in range (ch_number):\n",
    "            train_img_2[i][j] = np.delete(train_img_shuffle[i][j], window_len, axis=0)\n",
    "            \n",
    "    #################################################################################################\n",
    "    # Create Model\n",
    "    train_label = to_categorical(train_label, subject_number)\n",
    "    test_label = to_categorical(test_label, subject_number)\n",
    "\n",
    "    x_train =train_img_2[:20000]\n",
    "    y_train =train_label[:20000]\n",
    "\n",
    "    x_valid =train_img_2[20000:]\n",
    "    y_valid =train_label[20000:]\n",
    "\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3,3), activation = 'relu', padding='same', input_shape = (ch_number,window_len,160), data_format= \"channels_first\" ))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(256, (3,3), activation = 'relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(subject_number, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss= 'categorical_crossentropy',\n",
    "                  optimizer= optimizers.RMSprop(lr= 1e-4),\n",
    "                  metrics = ['acc'])\n",
    "    \n",
    "    #################################################################################################\n",
    "    # Train the Model\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs = 1,\n",
    "        batch_size = 20,\n",
    "        validation_data = (x_valid, y_valid))\n",
    "    \n",
    "    #################################################################################################\n",
    "    # Evalute the Model\n",
    "    TestResult=model.evaluate(test_img, test_label)\n",
    "    \n",
    "    #################################################################################################\n",
    "    # Save Result\n",
    "    SearchSpaceResult[IndexCh][0]=history.history['loss'][0]\n",
    "    SearchSpaceResult[IndexCh][1]=history.history['acc'][0]\n",
    "    SearchSpaceResult[IndexCh][2]=history.history['val_loss'][0]\n",
    "    SearchSpaceResult[IndexCh][3]=history.history['val_acc'][0]\n",
    "    \n",
    "    SearchSpaceResult[IndexCh][4]=TestResult[0]\n",
    "    SearchSpaceResult[IndexCh][5]=TestResult[1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5i7PMlbT96iD",
    "outputId": "c904ebaf-5b7e-4515-cbce-d2902acdd7e2"
   },
   "outputs": [],
   "source": [
    "## Visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hyFYHNEVPL2M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6895378604149642], 'acc': [0.5216277769735475]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2Ch_Base_Normal_Orthogonal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
